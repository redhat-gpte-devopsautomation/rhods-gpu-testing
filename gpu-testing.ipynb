{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddc0a7f-c6d4-4060-9d7e-e65dab5237e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "This is a sample jupyterhub notebook to test that GPU's are available for your environment and also to run a small tensor based / CUDA based python program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4ff6ba-f50d-4323-8a1c-b754bbb46cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "Install required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06451384-b5c8-4bb9-ac6f-a84b6d18b301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /opt/app-root/lib/python3.9/site-packages (2.11.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/app-root/lib/python3.9/site-packages (from tensorflow) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/app-root/lib/python3.9/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /opt/app-root/lib/python3.9/site-packages (from tensorflow) (2.0.7)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /opt/app-root/lib/python3.9/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/app-root/lib/python3.9/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/app-root/lib/python3.9/site-packages (from tensorflow) (1.56.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /opt/app-root/lib/python3.9/site-packages (from tensorflow) (3.9.0)\n",
      "Requirement already satisfied: keras<2.12,>=2.11.0 in /opt/app-root/lib/python3.9/site-packages (from tensorflow) (2.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/app-root/lib/python3.9/site-packages (from tensorflow) (16.0.0)\n",
      "Requirement already satisfied: numpy>=1.20 in /opt/app-root/lib/python3.9/site-packages (from tensorflow) (1.24.4)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/app-root/lib/python3.9/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /opt/app-root/lib/python3.9/site-packages (from tensorflow) (21.3)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /opt/app-root/lib/python3.9/site-packages (from tensorflow) (3.19.6)\n",
      "Requirement already satisfied: setuptools in /opt/app-root/lib/python3.9/site-packages (from tensorflow) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/app-root/lib/python3.9/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: tensorboard<2.12,>=2.11 in /opt/app-root/lib/python3.9/site-packages (from tensorflow) (2.11.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /opt/app-root/lib/python3.9/site-packages (from tensorflow) (2.11.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/app-root/lib/python3.9/site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/app-root/lib/python3.9/site-packages (from tensorflow) (4.7.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/app-root/lib/python3.9/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/app-root/lib/python3.9/site-packages (from tensorflow) (0.32.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/app-root/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/app-root/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.21.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/app-root/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/app-root/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (3.4.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/app-root/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/app-root/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/app-root/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/app-root/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.3.6)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/app-root/lib/python3.9/site-packages (from packaging->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/app-root/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/app-root/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/app-root/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (4.9)\n",
      "Requirement already satisfied: urllib3<2.0 in /opt/app-root/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (1.26.16)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/app-root/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /opt/app-root/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow) (6.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/app-root/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/app-root/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/app-root/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2023.5.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/app-root/lib/python3.9/site-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/app-root/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow) (3.16.0)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/app-root/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/app-root/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow) (3.2.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a955d4e8-a48f-4794-8fcb-18f709440150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting py3nvml\n",
      "  Downloading py3nvml-0.2.7-py3-none-any.whl (55 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.5/55.5 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting xmltodict (from py3nvml)\n",
      "  Downloading xmltodict-0.13.0-py2.py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: xmltodict, py3nvml\n",
      "Successfully installed py3nvml-0.2.7 xmltodict-0.13.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install py3nvml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94504808-0352-4319-a475-64739373e172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.0.1-cp39-cp39-manylinux1_x86_64.whl (619.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m120.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /opt/app-root/lib/python3.9/site-packages (from torch) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions in /opt/app-root/lib/python3.9/site-packages (from torch) (4.7.1)\n",
      "Requirement already satisfied: sympy in /opt/app-root/lib/python3.9/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/app-root/lib/python3.9/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/app-root/lib/python3.9/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /opt/app-root/lib/python3.9/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /opt/app-root/lib/python3.9/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /opt/app-root/lib/python3.9/site-packages (from torch) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /opt/app-root/lib/python3.9/site-packages (from torch) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /opt/app-root/lib/python3.9/site-packages (from torch) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /opt/app-root/lib/python3.9/site-packages (from torch) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /opt/app-root/lib/python3.9/site-packages (from torch) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /opt/app-root/lib/python3.9/site-packages (from torch) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /opt/app-root/lib/python3.9/site-packages (from torch) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /opt/app-root/lib/python3.9/site-packages (from torch) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /opt/app-root/lib/python3.9/site-packages (from torch) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /opt/app-root/lib/python3.9/site-packages (from torch) (2.0.0)\n",
      "Requirement already satisfied: setuptools in /opt/app-root/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (68.0.0)\n",
      "Requirement already satisfied: wheel in /opt/app-root/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.38.4)\n",
      "Requirement already satisfied: cmake in /opt/app-root/lib/python3.9/site-packages (from triton==2.0.0->torch) (3.27.2)\n",
      "Requirement already satisfied: lit in /opt/app-root/lib/python3.9/site-packages (from triton==2.0.0->torch) (16.0.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/app-root/lib/python3.9/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/app-root/lib/python3.9/site-packages (from sympy->torch) (1.3.0)\n",
      "Installing collected packages: torch\n",
      "Successfully installed torch-2.0.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f0291e-08f1-4b80-b6a3-6b15974a3e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Run a sample program using tensorflow library to test GPU's available and how many for this notebook?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61402463-c4c3-45a6-8b06-ce57ff1ad6d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-21 06:52:12.301779: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-21 06:52:13.542661: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-08-21 06:52:13.542799: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-08-21 06:52:13.542816: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU found\n",
      "Number of available GPUs: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-21 06:52:14.973694: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-21 06:52:15.017616: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-21 06:52:15.047585: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-21 06:52:15.047860: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-21 06:52:15.198748: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-21 06:52:15.199008: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-21 06:52:15.199258: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-21 06:52:15.199432: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /device:GPU:0 with 14792 MB memory:  -> device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:1e.0, compute capability: 7.0\n",
      "2023-08-21 06:52:15.200363: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-21 06:52:15.200591: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-21 06:52:15.200788: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Check if a GPU is available\n",
    "if tf.test.gpu_device_name():\n",
    "    print('GPU found')\n",
    "else:\n",
    "    print(\"No GPU found\")\n",
    "\n",
    "# Get the number of available GPUs\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(f\"Number of available GPUs: {len(gpus)}\")\n",
    "else:\n",
    "    print(\"No GPUs found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b4e88d-ec7f-40dc-b11c-cd35336828cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Use py3nvml to get details about the GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b02b3946-02c8-4472-a406-52141f7bc601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: Tesla V100-SXM2-16GB\n",
      "Memory usage: 541.62 MB\n",
      "Temperature: 43 C\n",
      "Power usage: 43.94 W\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import py3nvml\n",
    "\n",
    "# Initialize the NVML library\n",
    "py3nvml.py3nvml.nvmlInit()\n",
    "\n",
    "# Get the number of available GPUs\n",
    "num_gpus = py3nvml.py3nvml.nvmlDeviceGetCount()\n",
    "\n",
    "# Loop through all available GPUs and print their information\n",
    "for i in range(num_gpus):\n",
    "    handle = py3nvml.py3nvml.nvmlDeviceGetHandleByIndex(i)\n",
    "    print(f\"GPU {i}: {py3nvml.py3nvml.nvmlDeviceGetName(handle)}\")\n",
    "    print(f\"Memory usage: {py3nvml.py3nvml.nvmlDeviceGetMemoryInfo(handle).used / 1024**2:.2f} MB\")\n",
    "    print(f\"Temperature: {py3nvml.py3nvml.nvmlDeviceGetTemperature(handle, py3nvml.py3nvml.NVML_TEMPERATURE_GPU)} C\")\n",
    "    print(f\"Power usage: {py3nvml.py3nvml.nvmlDeviceGetPowerUsage(handle) / 1000:.2f} W\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5102db-6646-461f-ae34-3d32f0dc009e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Use subprocess to get mmore details about NVIDIA GPU's using nvidia-smi cli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33eabcb2-6ae7-4a9e-86c7-e9f127e31ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Aug 21 06:52:20 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.86.10              Driver Version: 535.86.10    CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla V100-SXM2-16GB           On  | 00000000:00:1E.0 Off |                    0 |\n",
      "| N/A   43C    P0              43W / 300W |    308MiB / 16384MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "+---------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "# Run the nvidia-smi command and capture its output\n",
    "output = subprocess.check_output(['nvidia-smi'])\n",
    "\n",
    "# Print the output\n",
    "print(output.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a4328f-8771-416a-9a74-6592cd2dd16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Run a sample neural network based program to rn on GPU's when detected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f65c8b23-cade-4b22-8f29-604e49d900e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Net(\n",
      "  (fc1): Linear(in_features=10, out_features=5, bias=True)\n",
      "  (fc2): Linear(in_features=5, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Check if a GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Define a simple neural network\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(10, 5)\n",
    "        self.fc2 = nn.Linear(5, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Create a random input tensor\n",
    "input_tensor = torch.randn(1, 10)\n",
    "\n",
    "# Move the input tensor to the GPU\n",
    "input_tensor = input_tensor.to(device)\n",
    "\n",
    "# Create a neural network and move it to the GPU\n",
    "net = Net().to(device)\n",
    "\n",
    "# Define a loss function and an optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "\n",
    "# Train the neural network\n",
    "for i in range(100):\n",
    "    # Zero the gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward pass\n",
    "    output_tensor = net(input_tensor)\n",
    "\n",
    "    # Compute the loss\n",
    "    target_tensor = torch.randn(1, 1)\n",
    "    target_tensor = target_tensor.to(device)\n",
    "    loss = criterion(output_tensor, target_tensor)\n",
    "\n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "\n",
    "    # Update the weights\n",
    "    optimizer.step()\n",
    "\n",
    "# Print the trained model\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e08723-e907-4c25-95af-2206e2f92eb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.16",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
